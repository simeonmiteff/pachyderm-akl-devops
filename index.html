<!DOCTYPE html>
<html>
  <head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1172120-8"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-1172120-8');
    </script>
    <title>Data pipelines on Kubernetes with Pachyderm</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <link rel="stylesheet" type="text/css" href="css/xerra-font.css">
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <link rel="preload" href="fonts/SuisseIntl-Book.otf" as="font" crossorigin>
    <link rel="preload" href="fonts/SuisseIntl-Regular.otf" as="font" crossorigin>
    <link rel="preload" href="fonts/SuisseIntl-Bold.otf" as="font" crossorigin>
    <link rel="preload" href="fonts/SuisseIntl-RegularItalic.otf" as="font" crossorigin>
    <link rel="preload" href="fonts/SuisseIntl-BoldItalic.otf" as="font" crossorigin>
  </head>
  <body>
    <textarea id="source">
class: x_blank x_redbg
exclude: true

---

class: x_blank x_redbg x_logocentre

---

class: x_redbg x_titleslide
.x_title[DATA PIPELINES ON KUBERNETES WITH PACHYDERM]

.x_footer[
.x_footerlogo[
]
]

---
class: x_blank x_redbg
## `$ whoami`

.x_left-column30[
![Simeon Miteff](figures/simeon_miteff.jpg)
]
.x_right-column70[
.x_personname[
Simeon Miteff
]
.x_persontitle[
Senior Software Engineer
]
]

---
class: center, middle
# The DevOps context

---
class: left
background-image: url(figures/k8s_1.svg)
## Servers

---
class: left
background-image: url(figures/k8s_2.svg)
## Containers

---
class: left
background-image: url(figures/k8s_3.svg)
## Container orchestration (Kubernetes)

---
class: left
background-image: url(figures/pach_k8s.svg)
## Pipeline frameworks (Pachyderm)

---
class: center, middle
# Story time

---
class: left
background-image: url(figures/crawling.svg)
## First attempt (re-inventing the wheel)

---
class: center

&nbsp; 
.hugefont[&#x1F914;]
&nbsp;          
&nbsp; 
&nbsp; 
Hmmm... how many times has this wheel been invented?

---
class: left
background-image: url(figures/awesome1.png)

---
class: left
background-image: url(figures/awesome2.png)

---
class: left
background-image: url(figures/awesome3.png)

---
class: center

&nbsp; 
.hugefont[&#x1F92F;]
&nbsp;          
&nbsp; 
&nbsp; 
Yikes - over 120 times...

---
## Second attempt

We studied a few _managed/hosted_ options:
- Dataflow (Apache Beam)
- Cloud Dataproc
- Cloud Composer (Apache Airflow)

Airflow seemed to be the most flexible, and cheap/quick to test.

--
## Failure (Airflow)
My test was negative. Tried for about a week, and found:
- Python-centric, with poor dependency management.
- No data handling and obscure means to communicate between stages.
- Running a Kubernetes container is supported, but my attempt failed (no logs!).

---
## Third attempt

### Also known as: third time lucky.

Next I looked for first-class (only-class) Kubernetes support:
- Argo
- Kubeflow
- Pachyderm

Our R&amp;D team wanted data provenance features, so we tried Pachyderm next. 

---
class: center, middle
# A (short) lecture

---
## What is Pachyderm?

- https://pachyderm.io/
- "Git for data science" _(aaargh!, what is git?)_
- An ETL _(too many TLAs!)_
&nbsp;          
&nbsp; 

--
![Example Pachyderm DAG](figures/ml.png)

---
## Core concepts

- Data are _versioned_ (overwriting a file with _different_ contents creates a new version).
- Pipelines can be anything that can run on Linux (language and run-time independent).
- Results can be tracked to the exact inputs and code used to produce them (provenance).

---
## Details (the _wall of text_)

- Each pipeline has an output "_data repository" (repo)_.
- A versioned file in a repo is called a _datum_.
- Pipelines can (but don't have to) reference repos as _inputs_.
- Pipelines are made up of 1 or more _workers_.
- Workers are based on the pipeline container image.
- Pachyderm executes a command from your container (a _job_).
- The _glob pattern_ in an input determine datum-to-job mapping.
- For 1:1 mapping, each worker will handle one job (parallelism).
- You specify resources needed by a job (RAM, CPU).
- Kubernetes takes care of scheduling workers.

---
## Getting data in and out

- A pipeline can write new datums (downloading them, for example).
- You can upload to a repo by hand: `pachctl put file`.
- You can download to by hand also: `pachctl get file`.
- Defining an _egress_ pushes output datums to external object stores (so _buckets_, e.g. AWS S3, Google Cloud Storage, Azure something).

---
## Scaling out

By default:
- One worker will be started on each server.
- Parallel jobs will execute over all workers.

This works well for fixed server resources, but is inefficient when renting them. We can fix that:
- Tell Pachyderm to put pipelines in `standby` (shut down idle workers).
- Override the level of parallelism to be more than the minimum cluster size.
- Set the cluster to auto-scale on demand (cloud-specific Kubernetes control plane feature).
- Specify resource requirements in pipelines to get the Kubernetes scheduler to trigger auto-scaling.

---
class: center, middle
# Demo time!

---
## Trying it on your laptop

Follow along here:

.smallfont[https://docs.pachyderm.io/en/latest/getting_started/beginner_tutorial.html]

I pre-prepared using these commands:
```
$ wget \
https://github.com/kubernetes/minikube/releases/download/v1.5.2/minikube_1.5.2.deb
$ sudo dpkg -i minikube_1.5.2.deb
$ minikube start
$ wget \
https://github.com/pachyderm/pachyderm/releases/download/v1.9.9/pachctl_1.9.9_amd64.deb
$ sudo dpkg -i pachctl_1.9.9_amd64.deb
$ pachctl deploy local
```
If you see this, things are going well:
```
$ pachctl version
COMPONENT           VERSION             
pachctl             1.9.9               
pachd               1.9.9
```

---
class: center, middle
# In conclusion...

---
## What I don't like

Non-admin user (un)friendliness:
- Assumes `kubectl` access to the K8s cluster.
- The `pachctl` CLI takes a while to learn.
- When things go properly wrong, requires wielding `kubectl`.

I found more than one way to accidentally clobber a cluster:
- https://github.com/pachyderm/pachyderm/issues/4169
- https://github.com/pachyderm/pachyderm/issues/4168

The "Enterprise edition" features are too expensive:
- Web interface.
- Access control.
- Advanced statistics.

---
## Introducing `pachplot`

I built a simple tool to visualise your pipelines and repos (the DAG):

https://github.com/simeonmiteff/pachplot

It queries the cluster via the API and draws a graph.

![Pachplot example output](figures/example_output.png)

---
class: x_redbg x_blank
## Thank you!

.x_footer[
.x_footerlogo[
]
]

   </textarea>
    <script src="./js/remark-latest.min.js" type="text/javascript"></script>
    
    <script type="text/javascript">
        var slideshow = remark.create({
            navigation: {
                click: false
            },
            properties: {
                class: "center, middle"
            },
            countIncrementalSlides: false
        });
    </script>
</body>
</html>
